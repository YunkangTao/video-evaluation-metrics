#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è§†é¢‘åŠ¨æ€ç¨‹åº¦è¯„ä¼°è„šæœ¬
ä½¿ç”¨ RAFT å…‰æµæ¨¡å‹è¯„ä¼°è§†é¢‘çš„åŠ¨æ€ç¨‹åº¦
"""

import argparse
import os
import sys
import cv2
import glob
import numpy as np
import torch
from tqdm import tqdm
from easydict import EasyDict as edict
import json
from datetime import datetime


# ============== RAFT æ¨¡å‹ç›¸å…³ ==============
# éœ€è¦å…ˆå…‹éš† RAFT ä»“åº“å¹¶æ·»åŠ åˆ°è·¯å¾„
# git clone https://github.com/princeton-vl/RAFT.git

def setup_raft_path(raft_path=None):
    """è®¾ç½® RAFT è·¯å¾„"""
    if raft_path is None:
        # é»˜è®¤åœ¨å½“å‰ç›®å½•æˆ–ä¸Šçº§ç›®å½•æŸ¥æ‰¾
        possible_paths = [
            './RAFT',
            '../RAFT',
            './RAFT/core',
            os.path.expanduser('~/RAFT'),
        ]
        for p in possible_paths:
            if os.path.exists(p):
                raft_path = p
                break
    
    if raft_path is None:
        raise RuntimeError(
            "æ‰¾ä¸åˆ° RAFT ç›®å½•ã€‚è¯·å…ˆå…‹éš† RAFT ä»“åº“:\n"
            "git clone https://github.com/princeton-vl/RAFT.git"
        )
    
    # æ·»åŠ åˆ°ç³»ç»Ÿè·¯å¾„
    core_path = os.path.join(raft_path, 'core') if 'core' not in raft_path else raft_path
    if core_path not in sys.path:
        sys.path.insert(0, raft_path)
        sys.path.insert(0, core_path)
    
    return raft_path


class DynamicDegree:
    """è§†é¢‘åŠ¨æ€ç¨‹åº¦è¯„ä¼°å™¨ï¼ˆä½¿ç”¨RAFTæ¨¡å‹ï¼‰"""
    
    def __init__(self, args, device):
        self.args = args
        self.device = device
        self.params = None
        self.load_model()
    
    def load_model(self):
        """åŠ è½½ RAFT æ¨¡å‹"""
        from vbench.third_party.RAFT.core.raft import RAFT
        from vbench.third_party.RAFT.core.utils_core.utils import InputPadder
        self.InputPadder = InputPadder
        
        self.model = RAFT(self.args)
        
        if not os.path.exists(self.args.model):
            raise FileNotFoundError(
                f"æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶: {self.args.model}\n"
                "è¯·ä¸‹è½½ RAFT é¢„è®­ç»ƒæ¨¡å‹:\n"
                "wget https://dl.dropboxusercontent.com/s/4j4z58wuv8o0mfz/models.zip\n"
                "unzip models.zip"
            )
        
        ckpt = torch.load(self.args.model, map_location="cpu")
        # å¤„ç† DataParallel ä¿å­˜çš„æ¨¡å‹
        new_ckpt = {k.replace('module.', ''): v for k, v in ckpt.items()}
        self.model.load_state_dict(new_ckpt)
        self.model.to(self.device)
        self.model.eval()
        print(f"âœ“ RAFT æ¨¡å‹åŠ è½½æˆåŠŸ: {self.args.model}")
    
    def get_score(self, img, flo):
        """è®¡ç®—å…‰æµåˆ†æ•°ï¼ˆå– top 5% å…‰æµå¹…åº¦å‡å€¼ï¼‰"""
        img = img[0].permute(1, 2, 0).cpu().numpy()
        flo = flo[0].permute(1, 2, 0).cpu().numpy()
        
        u = flo[:, :, 0]
        v = flo[:, :, 1]
        rad = np.sqrt(np.square(u) + np.square(v))
        
        h, w = rad.shape
        rad_flat = rad.flatten()
        cut_index = int(h * w * 0.05)
        
        max_rad = np.mean(abs(np.sort(-rad_flat))[:cut_index])
        
        return max_rad.item()
    
    def set_params(self, frame, count):
        """æ ¹æ®è§†é¢‘åˆ†è¾¨ç‡å’Œå¸§æ•°è®¾ç½®åŠ¨æ€é˜ˆå€¼å‚æ•°"""
        scale = min(list(frame.shape)[-2:])
        self.params = {
            "thres": 6.0 * (scale / 256.0),
            "count_num": round(4 * (count / 16.0))
        }
    
    def infer(self, video_path):
        """
        æ¨ç†å•ä¸ªè§†é¢‘
        
        Returns:
            dict: åŒ…å«åŠ¨æ€ç¨‹åº¦è¯„ä¼°ç»“æœ
        """
        with torch.no_grad():
            if video_path.endswith('.mp4') or video_path.endswith('.avi') or video_path.endswith('.mov'):
                frames = self.get_frames(video_path)
            elif os.path.isdir(video_path):
                frames = self.get_frames_from_img_folder(video_path)
            else:
                raise NotImplementedError(f"ä¸æ”¯æŒçš„æ ¼å¼: {video_path}")
            
            if len(frames) < 2:
                return {
                    'is_dynamic': False,
                    'flow_scores': [],
                    'mean_flow_score': 0.0,
                    'max_flow_score': 0.0,
                    'num_frames': len(frames)
                }
            
            self.set_params(frame=frames[0], count=len(frames))
            
            flow_scores = []
            for image1, image2 in zip(frames[:-1], frames[1:]):
                padder = self.InputPadder(image1.shape)
                image1, image2 = padder.pad(image1, image2)
                _, flow_up = self.model(image1, image2, iters=20, test_mode=True)
                max_rad = self.get_score(image1, flow_up)
                flow_scores.append(max_rad)
            
            is_dynamic = self.check_move(flow_scores)
            
            return {
                'is_dynamic': is_dynamic,
                'flow_scores': flow_scores,
                'mean_flow_score': float(np.mean(flow_scores)) if flow_scores else 0.0,
                'max_flow_score': float(np.max(flow_scores)) if flow_scores else 0.0,
                'min_flow_score': float(np.min(flow_scores)) if flow_scores else 0.0,
                'std_flow_score': float(np.std(flow_scores)) if flow_scores else 0.0,
                'threshold': self.params['thres'],
                'count_threshold': self.params['count_num'],
                'num_frames': len(frames)
            }
    
    def check_move(self, score_list):
        """åˆ¤æ–­è§†é¢‘æ˜¯å¦ä¸ºåŠ¨æ€"""
        thres = self.params["thres"]
        count_num = self.params["count_num"]
        count = 0
        for score in score_list:
            if score > thres:
                count += 1
            if count >= count_num:
                return True
        return False
    
    def get_frames(self, video_path):
        """ä»è§†é¢‘æ–‡ä»¶ä¸­æå–å¸§"""
        frame_list = []
        video = cv2.VideoCapture(video_path)
        
        if not video.isOpened():
            raise ValueError(f"æ— æ³•æ‰“å¼€è§†é¢‘: {video_path}")
        
        fps = video.get(cv2.CAP_PROP_FPS)
        if fps <= 0:
            fps = 30
        
        interval = max(1, round(fps / 8))  # é‡‡æ ·åˆ°çº¦ 8fps
        
        while video.isOpened():
            success, frame = video.read()
            if success:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame = torch.from_numpy(frame.astype(np.uint8)).permute(2, 0, 1).float()
                frame = frame[None].to(self.device)
                frame_list.append(frame)
            else:
                break
        video.release()
        
        if not frame_list:
            raise ValueError(f"è§†é¢‘æ²¡æœ‰æœ‰æ•ˆå¸§: {video_path}")
        
        frame_list = self.extract_frame(frame_list, interval)
        return frame_list
    
    def extract_frame(self, frame_list, interval=1):
        """æŒ‰é—´éš”æå–å¸§"""
        extract = []
        for i in range(0, len(frame_list), interval):
            extract.append(frame_list[i])
        return extract
    
    def get_frames_from_img_folder(self, img_folder):
        """ä»å›¾ç‰‡æ–‡ä»¶å¤¹ä¸­åŠ è½½å¸§"""
        exts = ['jpg', 'png', 'jpeg', 'bmp', 'tif', 'tiff', 
                'JPG', 'PNG', 'JPEG', 'BMP', 'TIF', 'TIFF']
        frame_list = []
        imgs = sorted([
            p for p in glob.glob(os.path.join(img_folder, "*")) 
            if os.path.splitext(p)[1][1:] in exts
        ])
        
        for img in imgs:
            frame = cv2.imread(img, cv2.IMREAD_COLOR)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frame = torch.from_numpy(frame.astype(np.uint8)).permute(2, 0, 1).float()
            frame = frame[None].to(self.device)
            frame_list.append(frame)
        
        if not frame_list:
            raise ValueError(f"æ–‡ä»¶å¤¹ä¸­æ²¡æœ‰æœ‰æ•ˆå›¾ç‰‡: {img_folder}")
        
        return frame_list


def evaluate_video_folder(folder_path, model_path, output_path=None, 
                          device=None, save_flow_scores=False, raft_path=None):
    """
    è¯„ä¼°æ–‡ä»¶å¤¹ä¸­æ‰€æœ‰è§†é¢‘çš„åŠ¨æ€ç¨‹åº¦
    
    Args:
        folder_path: è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„
        model_path: RAFT æ¨¡å‹æƒé‡è·¯å¾„
        output_path: è¾“å‡º JSON æ–‡ä»¶è·¯å¾„
        device: è®¡ç®—è®¾å¤‡
        save_flow_scores: æ˜¯å¦ä¿å­˜è¯¦ç»†çš„å…‰æµåˆ†æ•°
        raft_path: RAFT ä»“åº“è·¯å¾„
    """
    # è®¾ç½® RAFT è·¯å¾„
    setup_raft_path(raft_path)
    
    # è®¾ç½®è®¾å¤‡
    if device is None:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    else:
        device = torch.device(device)
    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆå§‹åŒ–æ¨¡å‹
    args = edict({
        "model": model_path,
        "small": False,
        "mixed_precision": False,
        "alternate_corr": False
    })
    
    evaluator = DynamicDegree(args, device)
    
    # è·å–æ‰€æœ‰è§†é¢‘æ–‡ä»¶
    video_files = [
        f for f in os.listdir(folder_path)
        if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))
    ]
    video_files.sort()
    
    if not video_files:
        print(f"æ–‡ä»¶å¤¹ {folder_path} ä¸­æ²¡æœ‰æ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
        return None
    
    print(f"æ‰¾åˆ° {len(video_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    print("-" * 70)
    
    results = []
    
    for video_file in tqdm(video_files, desc="è¯„ä¼°åŠ¨æ€ç¨‹åº¦"):
        video_path = os.path.join(folder_path, video_file)
        prompt = os.path.splitext(video_file)[0]
        
        try:
            eval_result = evaluator.infer(video_path)
            
            # è®¡ç®—å½’ä¸€åŒ–åˆ†æ•° (0-100)
            dynamic_score = min(100, (eval_result['mean_flow_score'] / 30.0) * 100)
            
            result = {
                'video_file': video_file,
                'prompt': prompt,
                'video_path': video_path,
                'dynamic_score': round(dynamic_score, 2),
                'is_dynamic': eval_result['is_dynamic'],
                'mean_flow_score': round(eval_result['mean_flow_score'], 4),
                'max_flow_score': round(eval_result['max_flow_score'], 4),
                'min_flow_score': round(eval_result['min_flow_score'], 4),
                'std_flow_score': round(eval_result['std_flow_score'], 4),
                'threshold': round(eval_result['threshold'], 4),
                'count_threshold': eval_result['count_threshold'],
                'num_frames': eval_result['num_frames']
            }
            
            if save_flow_scores:
                result['flow_scores'] = [round(s, 4) for s in eval_result['flow_scores']]
            
            results.append(result)
            
        except Exception as e:
            print(f"\nâš  è¯„ä¼° {video_file} æ—¶å‡ºé”™: {e}")
            results.append({
                'video_file': video_file,
                'prompt': prompt,
                'video_path': video_path,
                'error': str(e)
            })
    
    # ç»Ÿè®¡ç»“æœ
    valid_results = [r for r in results if 'dynamic_score' in r]
    
    if valid_results:
        scores = [r['dynamic_score'] for r in valid_results]
        mean_flow_scores = [r['mean_flow_score'] for r in valid_results]
        dynamic_count = sum(1 for r in valid_results if r['is_dynamic'])
        
        summary = {
            'evaluation_time': datetime.now().isoformat(),
            'folder_path': os.path.abspath(folder_path),
            'model_path': model_path,
            'device': str(device),
            'total_videos': len(video_files),
            'evaluated_videos': len(valid_results),
            'failed_videos': len(video_files) - len(valid_results),
            'dynamic_videos': dynamic_count,
            'static_videos': len(valid_results) - dynamic_count,
            'dynamic_ratio': round(dynamic_count / len(valid_results) * 100, 2),
            'avg_dynamic_score': round(np.mean(scores), 2),
            'max_dynamic_score': round(np.max(scores), 2),
            'min_dynamic_score': round(np.min(scores), 2),
            'std_dynamic_score': round(np.std(scores), 2),
            'avg_mean_flow': round(np.mean(mean_flow_scores), 4),
        }
        
        # æ‰“å°ç»“æœ
        print("\n" + "=" * 70)
        print("ğŸ“Š è¯„ä¼°ç»“æœæ±‡æ€» (RAFT æ¨¡å‹)")
        print("=" * 70)
        print(f"æ€»è§†é¢‘æ•°:       {summary['total_videos']}")
        print(f"æˆåŠŸè¯„ä¼°:       {summary['evaluated_videos']}")
        print(f"è¯„ä¼°å¤±è´¥:       {summary['failed_videos']}")
        print("-" * 70)
        print(f"åŠ¨æ€è§†é¢‘:       {summary['dynamic_videos']} ({summary['dynamic_ratio']:.1f}%)")
        print(f"é™æ€è§†é¢‘:       {summary['static_videos']} ({100 - summary['dynamic_ratio']:.1f}%)")
        print("-" * 70)
        print(f"å¹³å‡åŠ¨æ€åˆ†æ•°:   {summary['avg_dynamic_score']:.2f} / 100")
        print(f"æœ€é«˜åŠ¨æ€åˆ†æ•°:   {summary['max_dynamic_score']:.2f} / 100")
        print(f"æœ€ä½åŠ¨æ€åˆ†æ•°:   {summary['min_dynamic_score']:.2f} / 100")
        print(f"åˆ†æ•°æ ‡å‡†å·®:     {summary['std_dynamic_score']:.2f}")
        print(f"å¹³å‡å…‰æµå¹…åº¦:   {summary['avg_mean_flow']:.4f}")
        print("=" * 70)
        
        # æ‰“å°è¯¦ç»†ç»“æœ
        print("\nğŸ“‹ è¯¦ç»†ç»“æœ (æŒ‰åŠ¨æ€åˆ†æ•°é™åºæ’åˆ—):")
        print("-" * 80)
        print(f"{'çŠ¶æ€':<6} | {'åˆ†æ•°':>6} | {'å…‰æµå‡å€¼':>8} | {'å¸§æ•°':>4} | {'Prompt':<40}")
        print("-" * 80)
        
        sorted_results = sorted(valid_results, key=lambda x: x['dynamic_score'], reverse=True)
        for r in sorted_results:
            status = "âœ“ åŠ¨æ€" if r['is_dynamic'] else "âœ— é™æ€"
            prompt_display = r['prompt'][:38] + '..' if len(r['prompt']) > 40 else r['prompt']
            print(f"{status:<6} | {r['dynamic_score']:>6.2f} | {r['mean_flow_score']:>8.2f} | {r['num_frames']:>4} | {prompt_display}")
        
        print("-" * 80)
    else:
        summary = {
            'evaluation_time': datetime.now().isoformat(),
            'folder_path': os.path.abspath(folder_path),
            'model_path': model_path,
            'total_videos': len(video_files),
            'evaluated_videos': 0,
            'error': 'No videos were successfully evaluated'
        }
    
    # ä¿å­˜ç»“æœ
    if output_path is None:
        output_path = os.path.join(folder_path, 'dynamic_degree_results.json')
    
    output_data = {
        'summary': summary,
        'results': results
    }
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}")
    
    # ä¿å­˜ CSV
    csv_path = output_path.replace('.json', '.csv')
    with open(csv_path, 'w', encoding='utf-8') as f:
        f.write("video_file,prompt,dynamic_score,is_dynamic,mean_flow_score,max_flow_score,num_frames\n")
        for r in results:
            if 'dynamic_score' in r:
                prompt_escaped = r['prompt'].replace('"', '""')
                f.write(f'"{r["video_file"]}","{prompt_escaped}",{r["dynamic_score"]},{r["is_dynamic"]},{r["mean_flow_score"]},{r["max_flow_score"]},{r["num_frames"]}\n')
    
    print(f"ğŸ“„ CSV ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
    
    return output_data


def main():
    parser = argparse.ArgumentParser(
        description='ä½¿ç”¨ RAFT æ¨¡å‹è¯„ä¼°è§†é¢‘åŠ¨æ€ç¨‹åº¦',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python dynamic_degree_raft.py /path/to/videos --model models/raft-things.pth
  python dynamic_degree_raft.py /path/to/videos --model models/raft-sintel.pth -o results.json
  python dynamic_degree_raft.py /path/to/videos --model models/raft-things.pth --device cuda:0

å‡†å¤‡å·¥ä½œ:
  1. å…‹éš† RAFT ä»“åº“:
     git clone https://github.com/princeton-vl/RAFT.git
  
  2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹:
     cd RAFT
     wget https://dl.dropboxusercontent.com/s/4j4z58wuv8o0mfz/models.zip
     unzip models.zip
  
  3. å®‰è£…ä¾èµ–:
     pip install torch torchvision opencv-python numpy tqdm easydict
        """
    )
    
    parser.add_argument(
        'folder',
        type=str,
        help='åŒ…å«è§†é¢‘æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„'
    )
    parser.add_argument(
        '--model', '-m',
        type=str,
        required=True,
        help='RAFT æ¨¡å‹æƒé‡è·¯å¾„ (å¦‚: models/raft-things.pth)'
    )
    parser.add_argument(
        '--output', '-o',
        type=str,
        default=None,
        help='è¾“å‡º JSON æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--device', '-d',
        type=str,
        default=None,
        help='è®¡ç®—è®¾å¤‡ (å¦‚: cuda:0, cpu)'
    )
    parser.add_argument(
        '--raft_path',
        type=str,
        default="./VBench/vbench/third_party/RAFT",
        help='RAFT ä»“åº“è·¯å¾„'
    )
    parser.add_argument(
        '--save_flow_scores',
        action='store_true',
        help='æ˜¯å¦ä¿å­˜æ¯å¸§çš„å…‰æµåˆ†æ•°'
    )
    
    args = parser.parse_args()
    
    if not os.path.isdir(args.folder):
        print(f"âŒ é”™è¯¯: {args.folder} ä¸æ˜¯æœ‰æ•ˆçš„æ–‡ä»¶å¤¹è·¯å¾„")
        return
    
    if not os.path.exists(args.model):
        print(f"âŒ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        print("è¯·ä¸‹è½½ RAFT é¢„è®­ç»ƒæ¨¡å‹")
        return
    
    evaluate_video_folder(
        folder_path=args.folder,
        model_path=args.model,
        output_path=args.output,
        device=args.device,
        save_flow_scores=args.save_flow_scores,
        raft_path=args.raft_path
    )


if __name__ == '__main__':
    main()